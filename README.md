# üí¨ Q/A ChatBot

Welcome to the **Q/A ChatBot**! This project is a Streamlit-based application that interacts with the powerful **LLAMA** model to answer user questions in an interactive chat interface. The bot can remember previous interactions and build context-aware responses for a more engaging conversation.

---

## üõ†Ô∏è Tech Stack

The following technologies have been used to build the ChatBot:

| **Tech**      | **Description**                             | **Icon** |
|---------------|---------------------------------------------|----------|
| Streamlit     | Frontend for interactive web applications.  | ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit&logoColor=white) |
| Python        | Programming language for backend logic.     | ![Python](https://img.shields.io/badge/Python-3670A0?logo=python&logoColor=white) |
| LLAMA         | Language model API for natural language processing. | ![AI](https://img.shields.io/badge/LLAMA-AI%20Model-blue) |
| OpenAI/LLMs   | API to generate language-based completions. | ![OpenAI](https://img.shields.io/badge/OpenAI-%23000000.svg?logo=openai&logoColor=white) |

---

## üöÄ Features

- **Interactive Chat Interface**: Engage in real-time conversations with an AI assistant.
- **Context-Aware Responses**: The bot can reference past conversations to provide more meaningful answers.
- **LLAMA Model Integration**: Utilizes advanced AI models for text completion.
- **Persistent Chat History**: Conversations are stored in session and can be referenced in future queries.

---

## üíª Setup Instructions

Follow these steps to set up the project locally:

1. **Clone the Repository**:
    ```bash
    git clone https://github.com/your-username/qa-chatbot.git
    cd qa-chatbot
    ```

2. **Install Dependencies**:
    You can use `pip` to install all required packages:
    ```bash
    pip install -r requirements.txt
    ```

3. **Run the Application**:
    To launch the chatbot, use Streamlit:
    ```bash
    streamlit run app.py
    ```

---

## üîß Configuration

- You need an API key for the LLAMA model (or any other language model you are using). Store this key in an environment variable:
    ```bash
    export API_KEY="your_llama_api_key"
    ```

---



## ü§ù Contributing

Contributions are welcome! If you'd like to improve this project, please fork the repository and submit a pull request. For major changes, please open an issue to discuss what you would like to change.

1. Fork the project.
2. Create a feature branch (`git checkout -b feature/AmazingFeature`).
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4. Push to the branch (`git push origin feature/AmazingFeature`).
5. Open a pull request.

---


## üôè Acknowledgements

- Thanks to [Streamlit](https://streamlit.io/) for creating such an easy-to-use web framework.
- Special thanks to the developers of **LLAMA** for providing an amazing language model.

---
 
